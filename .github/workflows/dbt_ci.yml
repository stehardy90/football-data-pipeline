name: CI/CD Pipeline for dbt

on:
  push:
    branches:
      - master  
  pull_request:
    branches:
      - master

jobs:
  dbt_test:
    runs-on: ubuntu-latest

    steps:
    - name: Check out repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install dbt-core dbt-bigquery

    - name: Set environment variable for Google Cloud Credentials
      env:
        GOOGLE_CREDENTIALS_JSON: ${{ secrets.DOCKER_GOOGLE_APPLICATION_CREDENTIALS }}
      run: |
        echo "$GOOGLE_CREDENTIALS_JSON" > /tmp/gcp_credentials.json  
        ls -la /tmp/gcp_credentials.json  
        cat /tmp/gcp_credentials.json  

    - name: Set up Google Cloud Credentials
      run: |
        export DOCKER_GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp_credentials.json"
        echo $DOCKER_GOOGLE_APPLICATIONS_CREDENTIALS

    - name: Set up dbt profile
      run: |
        mkdir -p ~/.dbt
        cp config/dbt/profiles.yml ~/.dbt/profiles.yml  

    - name: Run dbt models
      env:
        GCP_PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}  
        BIGQUERY_DATASET: ${{ vars.BIGQUERY_DATASET }}  
        DOCKER_GOOGLE_APPLICATION_CREDENTIALS: /tmp/gcp_credentials.json  
      run: |
        dbt deps  # Install dbt packages
        dbt run
      working-directory: ./src/transform  

    - name: Run dbt tests
      env:
        GCP_PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}  
        BIGQUERY_DATASET: ${{ vars.BIGQUERY_DATASET }}  
        DOCKER_GOOGLE_APPLICATION_CREDENTIALS: /tmp/gcp_credentials.json  
      run: |
        dbt test
      working-directory: ./src/transform  
      
  docker_and_airflow_test:
    runs-on: ubuntu-latest

    steps:
    - name: Check out repository
      uses: actions/checkout@v2
      
    - name: Install Docker Compose
      run: |
        sudo apt-get update
        sudo apt-get install docker-compose -y
        
    - name: Set up Google Cloud Credentials
      run: |
        export DOCKER_GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp_credentials.json"
        export LOCAL_GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp_credentials.json"
        
    - name: Create empty .env file
      run: |
        touch docker/.env  # Create an empty .env file in the correct path

    - name: Run Docker Compose
      env:
        DOCKER_GOOGLE_APPLICATION_CREDENTIALS: /tmp/gcp_credentials.json
        LOCAL_GOOGLE_APPLICATION_CREDENTIALS: /tmp/gcp_credentials.json
      working-directory: ./docker  # Ensure you are in the correct directory
      run: |
        docker-compose up --build -d
        docker-compose ps  # Ensure the containers are in a healthy state

    - name: Verify Docker Health Check
      working-directory: ./docker  # Ensure you are in the correct directory
      run: |
        docker-compose ps  
        
    - name: Print Airflow webserver logs
      run: docker logs airflow-webserver

    - name: Wait for Airflow health check
      run: |
        max_retries=10  # Set a limit for the number of retries
        retries=0
        until docker exec airflow-webserver curl --fail http://localhost:8080/health; do
          if [ $retries -ge $max_retries ]; then
            echo "Max retries reached, exiting..."
            exit 1
          fi
          echo "Waiting for Airflow to be ready... (retry: $retries)"
          retries=$((retries+1))
          sleep 10
        done
        


