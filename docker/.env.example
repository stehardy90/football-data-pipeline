# Local path to your Google Cloud service account JSON credentials
# (Used by Docker to mount your credentials file into the container)
LOCAL_GOOGLE_APPLICATION_CREDENTIALS=C:/path/to/your/GoogleCloudServiceAccount.json

# Path to your Google Cloud service account JSON credentials inside the Docker container
# (This is where Docker will mount the credentials file for access within the container. Likely doesn't need to change)
DOCKER_GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/gcp_credentials.json

# Google Cloud project ID where your BigQuery datasets and resources are located
# Example: football-data-pipeline
GCP_PROJECT_ID=your-google-cloud-project-id

# BigQuery dataset name where raw, staging, and transformed tables will be stored
# Example: football_data_bronze
BIGQUERY_DATASET=your-dataset-name

# Location of your BigQuery dataset (this is the region where your BigQuery resources are hosted)
# Example: US or EU
BIGQUERY_LOCATION=your-location

# Docker Compose project name (used to namespace services in Docker Compose)
# This helps avoid conflicts if you're running multiple projects using Docker Compose
COMPOSE_PROJECT_NAME=docker-compose-project-name

# API key for football-data.org (used to authenticate and access football data via the API)
# Example: 34kj234fj3423ae2424bc23432de
API_KEY=your-football-api-key

# API resources to ingest data from, represented as a comma-separated list
# Modify based on the endpoints you need (competitions, standings, teams, etc.)
API_RESOURCES=competitions,standings,teams,matches,scorers

# List of competition IDs to ingest data for, represented as a comma-separated list
# Example: 2021 for Premier League, 2014 for La Liga, 2002 for Bundesliga
COMPETITION_IDS=2021,2014,2002
